"""
å¤šæ¨¡æ€è¾“å…¥å¤„ç†æ¨¡å—
å¤„ç†åŒ…å«è¡¨æƒ…å’Œè¯­éŸ³ç‰¹å¾çš„æ¸¸æˆå›åˆ
"""

from typing import Dict, Optional, List, Generator
import json
from core.multimodal_analyzer import MultimodalAnalyzer
from core.emotion_state import MicroExpressionFeatures, VoiceEmotionFeatures


class MultimodalInputHandler:
    """å¤šæ¨¡æ€è¾“å…¥å¤„ç†å™¨"""

    def __init__(self, orchestrator):
        self.orch = orchestrator
        self.analyzer = MultimodalAnalyzer()

    def process_multimodal_turn(
        self,
        session_id: str,
        text: str,
        emotion_features_dict: Optional[Dict] = None,
        voice_features_dict: Optional[Dict] = None,
    ) -> Generator:
        """
        å¤„ç†åŒ…å«è¡¨æƒ…å’Œè¯­éŸ³ç‰¹å¾çš„æ¸¸æˆå›åˆ

        Args:
            session_id: ä¼šè¯ID
            text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            emotion_features_dict: è¡¨æƒ…ç‰¹å¾å­—å…¸ï¼ˆå¯é€‰ï¼‰
            voice_features_dict: è¯­éŸ³ç‰¹å¾å­—å…¸ï¼ˆå¯é€‰ï¼‰

        Yields:
            åŒ…å«å¤šæ¨¡æ€åˆ†æç»“æœçš„æ›´æ–°
        """
        # è§£æç‰¹å¾
        emotion_features = None
        voice_features = None

        if emotion_features_dict:
            try:
                emotion_features = MicroExpressionFeatures.from_dict(
                    emotion_features_dict
                )
            except Exception as e:
                print(f"[Multimodal] è§£æè¡¨æƒ…ç‰¹å¾å¤±è´¥: {e}")

        if voice_features_dict:
            try:
                voice_features = VoiceEmotionFeatures.from_dict(voice_features_dict)
            except Exception as e:
                print(f"[Multimodal] è§£æè¯­éŸ³ç‰¹å¾å¤±è´¥: {e}")

        # å¤šæ¨¡æ€åˆ†æ
        emotion_dict = emotion_features.to_dict() if emotion_features else None
        voice_dict = voice_features.to_dict() if voice_features else None
        multimodal_result = self.analyzer.analyze_multimodal(
            text=text, emotion_features=emotion_dict, voice_features=voice_dict
        )

        # è·å–çŠ¶æ€å›¾æ ‡
        status_icons = self.analyzer.get_status_icons()

        # æ„å»ºç»“æœæ‘˜è¦
        result_summary = {
            "overall_score": multimodal_result["overall_score"],
            "breakdown": multimodal_result["breakdown"],
            "feedback": multimodal_result["feedback"],
            "inconsistencies": multimodal_result["inconsistencies"],
            "suggestions": multimodal_result["suggestions"],
            "emotion_analysis": multimodal_result["emotion_analysis"],
            "voice_analysis": multimodal_result["voice_analysis"],
            "status_icons": status_icons,
        }

        yield {"stage": "multimodal_analysis", "result": result_summary}

        # è¿”å›åˆ†æç»“æœå­—ç¬¦ä¸²ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        judgment = self._format_judgment(multimodal_result, status_icons)

        yield {
            "stage": "multimodal_complete",
            "judgment": judgment,
            "result": result_summary,
        }

    def _format_judgment(self, result: Dict, status_icons: Dict) -> str:
        """æ ¼å¼åŒ–è¯„ä¼°ç»“æœä¸ºå­—ç¬¦ä¸²"""
        lines = []

        # æ€»ä½“è¯„åˆ†
        lines.append(f"ğŸ“Š ç»¼åˆè¯„åˆ†: {result['overall_score']:.0f}/100")

        # åˆ†é¡¹å¾—åˆ†
        breakdown = result["breakdown"]
        lines.append(
            f"   æ–‡æœ¬: {breakdown['text']:.0f} | è¡¨æƒ…: {breakdown['emotion']:.0f} | è¯­éŸ³: {breakdown['voice']:.0f}"
        )

        # çŠ¶æ€å›¾æ ‡
        lines.append(
            f"   è¡¨æƒ…çŠ¶æ€: {status_icons['emotion_icon']} {status_icons['emotion_status']}"
        )
        lines.append(
            f"   è¯­éŸ³çŠ¶æ€: {status_icons['voice_icon']} {status_icons['voice_status']}"
        )

        # åé¦ˆ
        lines.append(f"   ğŸ’¡ {result['feedback']}")

        # ä¸ä¸€è‡´æ€§è­¦å‘Š
        if result["inconsistencies"]:
            lines.append(f"   âš ï¸ {' | '.join(result['inconsistencies'])}")

        # å»ºè®®
        if result["suggestions"]:
            lines.append(f"   ğŸ“ {result['suggestions'][0]}")

        return "\n".join(lines)

    def quick_analyze(
        self,
        emotion_features_dict: Optional[Dict] = None,
        voice_features_dict: Optional[Dict] = None,
    ) -> Dict:
        """
        å¿«é€Ÿåˆ†æï¼Œè¿”å›çŠ¶æ€å›¾æ ‡ï¼ˆç”¨äºå®æ—¶å±•ç¤ºï¼‰

        Returns:
            åŒ…å«çŠ¶æ€å›¾æ ‡çš„å­—å…¸
        """
        emotion_features = None
        voice_features = None

        if emotion_features_dict:
            try:
                emotion_features = EmotionFeatures.from_dict(emotion_features_dict)
            except:
                pass

        if voice_features_dict:
            try:
                voice_features = VoiceFeatures.from_dict(voice_features_dict)
            except:
                pass

        return self.analyzer.get_status_icons(
            emotion_features=emotion_features, voice_features=voice_features
        )
